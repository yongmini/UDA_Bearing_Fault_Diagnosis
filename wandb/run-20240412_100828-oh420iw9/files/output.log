04-12 10:08:29 imba: True
04-12 10:08:29 model_name: DANN
04-12 10:08:29 Domain: CWRU
04-12 10:08:29 source: JNU_0
04-12 10:08:29 target: JNU_1
04-12 10:08:29 data_dir: ./datasets
04-12 10:08:29 train_mode: single_source
04-12 10:08:29 cuda_device: 0
04-12 10:08:29 save_dir: ./ckpt/DANN/single_source
04-12 10:08:29 max_epoch: 30
04-12 10:08:29 batch_size: 64
04-12 10:08:29 num_workers: 0
04-12 10:08:29 signal_size: 2048
04-12 10:08:29 random_state: 2
04-12 10:08:29 normlizetype: mean-std
04-12 10:08:29 opt: sgd
04-12 10:08:29 lr: 0.001
04-12 10:08:29 momentum: 0.9
04-12 10:08:29 betas: (0.9, 0.999)
04-12 10:08:29 weight_decay: 0.0005
04-12 10:08:29 lr_scheduler: stepLR
04-12 10:08:29 gamma: 0.2
04-12 10:08:29 steps: 10
04-12 10:08:29 tradeoff: ['exp', 'exp', 'exp']
04-12 10:08:29 dropout: 0.0
04-12 10:08:29 save: False
04-12 10:08:29 load_path: 
04-12 10:08:29 tsne: True
04-12 10:08:29 save_path: ./ckpt/DANN/single_source/[JNU_0]To[JNU_1]_0412-100829
04-12 10:08:29 Detect 4 classes: ['1normal', 'ball', 'inner', 'outer']
04-12 10:08:30 using 1 / 1 gpus
Training data length: 1461
Testing data length: 732
Source Data Distribution:04-12 10:08:40 Source set JNU_0 number of samples 1460.

+--------------+---------+
| Label        |   Count |
|--------------+---------|
| 0            |     365 |
| 1            |     365 |
| 2            |     365 |
| 3            |     365 |
| Dataset Size |    1460 |
+--------------+---------+
Training data length: 1461
Testing data length: 732
04-12 10:08:47 target training set number of samples 249.
Target Data Distribution:
04-12 10:08:47 target validation set number of samples 488.
+--------------+---------+-------+
|              |   train |   val |
|--------------+---------+-------|
| 0            |     243 |   122 |
| 1            |       2 |   122 |
| 2            |       2 |   122 |
| 3            |       2 |   122 |
| Dataset Size |     249 |   488 |
+--------------+---------+-------+
04-12 10:08:47 -----Epoch 1/30-----
04-12 10:08:47 current lr: [0.001, 0.001]
  0%|          | 0/3 [00:00<?, ?it/s]100%|##########| 3/3 [00:00<00:00, 26.34it/s]100%|##########| 3/3 [00:00<00:00, 26.30it/s]
04-12 10:08:48 Train-Loss Source Classifier: 1.3961
04-12 10:08:48 Train-Loss Discriminator: 0.6868
04-12 10:08:48 Train-Acc Source Data: 0.2083
04-12 10:08:48 Train-Acc Discriminator: 50.0000
  0%|          | 0/8 [00:00<?, ?it/s]100%|##########| 8/8 [00:00<00:00, 148.76it/s]
04-12 10:08:48 Val-Acc Target Data: 0.2383
04-12 10:08:48 The best model epoch 1, val-acc 0.2383
  0%|          | 0/4 [00:00<?, ?it/s]100%|##########| 4/4 [00:00<00:00, 156.01it/s]
04-12 10:08:48 -----Epoch 2/30-----
04-12 10:08:48 current lr: [0.001, 0.001]
  0%|          | 0/4 [00:00<?, ?it/s] 75%|#######5  | 3/4 [00:00<00:00, 32.50it/s]
Traceback (most recent call last):
  File "train.py", line 95, in <module>
    trainer.train()
  File "/home/workspace/UDA_Bearing_Fault_Diagnosis/models/DANN.py", line 95, in train
    loss_c = F.cross_entropy(y_s, source_labels)
  File "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py", line 2962, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
ValueError: Expected input batch_size (61) to match target batch_size (64).
