04-12 10:10:19 imba: True
04-12 10:10:19 model_name: DANN
04-12 10:10:19 Domain: CWRU
04-12 10:10:19 source: JNU_0
04-12 10:10:19 target: JNU_1
04-12 10:10:19 data_dir: ./datasets
04-12 10:10:19 train_mode: single_source
04-12 10:10:19 cuda_device: 0
04-12 10:10:19 save_dir: ./ckpt/DANN/single_source
04-12 10:10:19 max_epoch: 30
04-12 10:10:19 batch_size: 64
04-12 10:10:19 num_workers: 0
04-12 10:10:19 signal_size: 2048
04-12 10:10:19 random_state: 2
04-12 10:10:19 normlizetype: mean-std
04-12 10:10:19 opt: sgd
04-12 10:10:19 lr: 0.001
04-12 10:10:19 momentum: 0.9
04-12 10:10:19 betas: (0.9, 0.999)
04-12 10:10:19 weight_decay: 0.0005
04-12 10:10:19 lr_scheduler: stepLR
04-12 10:10:19 gamma: 0.2
04-12 10:10:19 steps: 10
04-12 10:10:19 tradeoff: ['exp', 'exp', 'exp']
04-12 10:10:19 dropout: 0.0
04-12 10:10:19 save: False
04-12 10:10:19 load_path: 
04-12 10:10:19 tsne: True
04-12 10:10:19 save_path: ./ckpt/DANN/single_source/[JNU_0]To[JNU_1]_0412-101019
04-12 10:10:19 Detect 4 classes: ['1normal', 'ball', 'inner', 'outer']
04-12 10:10:20 using 1 / 1 gpus
Training data length: 1461
Testing data length: 732
Source Data Distribution:
+--------------+---------+
| Label        |   Count |
|--------------+---------|
| 0            |     365 |
| 1            |     365 |
| 2            |     365 |
| 3            |     365 |
| Dataset Size |    1460 |
+--------------+---------+
04-12 10:10:30 Source set JNU_0 number of samples 1460.
Training data length: 1461
Testing data length: 732
Target Data Distribution:04-12 10:10:37 target training set number of samples 249.

+--------------+---------+-------+
|              |   train |   val |
|--------------+---------+-------|
| 0            |     243 |   122 |
| 1            |       2 |   122 |
| 2            |       2 |   122 |
| 3            |       2 |   122 |
| Dataset Size |     249 |   488 |
+--------------+---------+-------+
04-12 10:10:37 target validation set number of samples 488.
04-12 10:10:37 -----Epoch 1/30-----
04-12 10:10:37 current lr: [0.001, 0.001]
  0%|          | 0/3 [00:00<?, ?it/s]100%|##########| 3/3 [00:00<00:00, 25.24it/s]100%|##########| 3/3 [00:00<00:00, 25.19it/s]
04-12 10:10:37 Train-Loss Source Classifier: 1.3961
04-12 10:10:37 Train-Loss Discriminator: 0.6868
04-12 10:10:37 Train-Acc Source Data: 0.2083
04-12 10:10:37 Train-Acc Discriminator: 50.0000
  0%|          | 0/7 [00:00<?, ?it/s]100%|##########| 7/7 [00:00<00:00, 160.40it/s]
04-12 10:10:37 Val-Acc Target Data: 0.2723
04-12 10:10:37 The best model epoch 1, val-acc 0.2723
  0%|          | 0/4 [00:00<?, ?it/s]100%|##########| 4/4 [00:00<00:00, 156.50it/s]
04-12 10:10:38 -----Epoch 2/30-----
04-12 10:10:38 current lr: [0.001, 0.001]
  0%|          | 0/4 [00:00<?, ?it/s] 75%|#######5  | 3/4 [00:00<00:00, 30.86it/s]
Traceback (most recent call last):
  File "train.py", line 95, in <module>
    trainer.train()
  File "/home/workspace/UDA_Bearing_Fault_Diagnosis/models/DANN.py", line 95, in train
    loss_c = F.cross_entropy(y_s, source_labels)
  File "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py", line 2962, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
ValueError: Expected input batch_size (61) to match target batch_size (64).
