04-14 06:21:51 imba: False
04-14 06:21:51 model_name: DANN
04-14 06:21:51 Domain: CWRU
04-14 06:21:51 source: JNU_1
04-14 06:21:51 target: JNU_2
04-14 06:21:51 data_dir: ./datasets
04-14 06:21:51 train_mode: single_source
04-14 06:21:51 cuda_device: 0
04-14 06:21:51 save_dir: ./ckpt/DANN/single_source
04-14 06:21:51 max_epoch: 50
04-14 06:21:51 batch_size: 128
04-14 06:21:51 num_workers: 0
04-14 06:21:51 signal_size: 2048
04-14 06:21:51 random_state: 75
04-14 06:21:51 normlizetype: mean-std
04-14 06:21:51 opt: sgd
04-14 06:21:51 lr: 0.001
04-14 06:21:51 momentum: 0.9
04-14 06:21:51 betas: (0.9, 0.999)
04-14 06:21:51 weight_decay: 0.0005
04-14 06:21:51 lr_scheduler: stepLR
04-14 06:21:51 gamma: 0.2
04-14 06:21:51 steps: 10
04-14 06:21:51 tradeoff: ['exp', 'exp', 'exp']
04-14 06:21:51 dropout: 0.0
04-14 06:21:51 save: False
04-14 06:21:51 load_path: 
04-14 06:21:51 tsne: False
04-14 06:21:51 save_path: ./ckpt/DANN/single_source/[JNU_1]To[JNU_2]_0414-062151
04-14 06:21:51 Detect 4 classes: ['1normal', 'ball', 'inner', 'outer']
04-14 06:21:53 using 1 / 1 gpus
Traceback (most recent call last):
  File "train.py", line 89, in <module>
    trainer = importlib.import_module(f"models.{args.model_name}").Trainset(args)
  File "/home/workspace/UDA_Bearing_Fault_Diagnosis/models/DANN.py", line 31, in __init__
    dropout=args.dropout).to(self.device)
  File "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  [Previous line repeated 3 more times]
  File "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
