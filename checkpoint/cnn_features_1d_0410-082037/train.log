04-10 08:20:37 method: multiDA
04-10 08:20:37 model_name: cnn_features_1d
04-10 08:20:37 data_name: CWRU
04-10 08:20:37 data_dir: /home/workspace/UDA_Bearing_Fault_Diagnosis/Data/CWRU/
04-10 08:20:37 transfer_task: [[1, 2], [0]]
04-10 08:20:37 normlizetype: mean-std
04-10 08:20:37 adabn: False
04-10 08:20:37 eval_all: False
04-10 08:20:37 adabn_epochs: 3
04-10 08:20:37 cuda_device: 0
04-10 08:20:37 checkpoint_dir: ./checkpoint
04-10 08:20:37 pretrained: False
04-10 08:20:37 batch_size: 64
04-10 08:20:37 num_workers: 0
04-10 08:20:37 bottleneck: True
04-10 08:20:37 bottleneck_num: 256
04-10 08:20:37 last_batch: False
04-10 08:20:37 distance_metric: False
04-10 08:20:37 distance_loss: MK-MMD
04-10 08:20:37 trade_off_distance: Step
04-10 08:20:37 lam_distance: 1
04-10 08:20:37 domain_adversarial: False
04-10 08:20:37 adversarial_loss: CDA+E
04-10 08:20:37 hidden_size: 1024
04-10 08:20:37 trade_off_adversarial: Step
04-10 08:20:37 lam_adversarial: 1
04-10 08:20:37 opt: adam
04-10 08:20:37 lr: 0.001
04-10 08:20:37 momentum: 0.9
04-10 08:20:37 weight_decay: 1e-05
04-10 08:20:37 lr_scheduler: step
04-10 08:20:37 gamma: 0.1
04-10 08:20:37 steps: 150, 250
04-10 08:20:37 middle_epoch: 50
04-10 08:20:37 max_epoch: 300
04-10 08:20:37 print_step: 50
04-10 08:20:37 using 1 gpus
04-10 08:20:40 -----Epoch 0/299-----
04-10 08:20:40 current lr: [0.001, 0.001, 0.001]
04-10 08:20:40 Epoch: 0 [0/2462], Train Loss: 2.3567 Train Acc: 0.0938,1535.9 examples/sec 0.04 sec/batch
04-10 08:20:40 Epoch: 0 source_train-Loss: 1.5507 source_train-Acc: 0.4342, Cost 0.2 sec
04-10 08:20:40 Epoch: 0 source_val-Loss: 0.9455 source_val-Acc: 0.6964, Cost 0.0 sec
04-10 08:20:40 Epoch: 0 target_val-Loss: 1.1761 target_val-Acc: 0.5939, Cost 0.0 sec
04-10 08:20:40 -----Epoch 1/299-----
04-10 08:20:40 current lr: [0.001, 0.001, 0.001]
04-10 08:20:40 Epoch: 1 [704/2462], Train Loss: 1.3868 Train Acc: 0.4927,10136.8 examples/sec 0.01 sec/batch
04-10 08:20:40 Epoch: 1 source_train-Loss: 0.7412 source_train-Acc: 0.7206, Cost 0.2 sec
04-10 08:20:40 Epoch: 1 source_val-Loss: 0.2687 source_val-Acc: 0.8961, Cost 0.0 sec
04-10 08:20:40 Epoch: 1 target_val-Loss: 0.3256 target_val-Acc: 0.8659, Cost 0.0 sec
04-10 08:20:40 -----Epoch 2/299-----
04-10 08:20:40 current lr: [0.001, 0.001, 0.001]
04-10 08:20:40 Epoch: 2 [1408/2462], Train Loss: 0.5292 Train Acc: 0.7941,10240.1 examples/sec 0.01 sec/batch
04-10 08:20:41 Epoch: 2 source_train-Loss: 0.3533 source_train-Acc: 0.8582, Cost 0.2 sec
04-10 08:20:41 Epoch: 2 source_val-Loss: 0.1704 source_val-Acc: 0.9334, Cost 0.0 sec
04-10 08:20:41 Epoch: 2 target_val-Loss: 0.3116 target_val-Acc: 0.8659, Cost 0.0 sec
04-10 08:20:41 -----Epoch 3/299-----
04-10 08:20:41 current lr: [0.001, 0.001, 0.001]
04-10 08:20:41 Epoch: 3 [2112/2462], Train Loss: 0.2482 Train Acc: 0.9040,10206.6 examples/sec 0.01 sec/batch
04-10 08:20:41 Epoch: 3 source_train-Loss: 0.2148 source_train-Acc: 0.9175, Cost 0.2 sec
04-10 08:20:41 Epoch: 3 source_val-Loss: 0.0799 source_val-Acc: 0.9821, Cost 0.0 sec
04-10 08:20:41 Epoch: 3 target_val-Loss: 0.1623 target_val-Acc: 0.9310, Cost 0.0 sec
04-10 08:20:41 -----Epoch 4/299-----
04-10 08:20:41 current lr: [0.001, 0.001, 0.001]
04-10 08:20:41 Epoch: 4 source_train-Loss: 0.1724 source_train-Acc: 0.9362, Cost 0.2 sec
04-10 08:20:41 Epoch: 4 source_val-Loss: 0.0604 source_val-Acc: 0.9773, Cost 0.0 sec
04-10 08:20:41 Epoch: 4 target_val-Loss: 0.0953 target_val-Acc: 0.9732, Cost 0.0 sec
04-10 08:20:41 -----Epoch 5/299-----
04-10 08:20:41 current lr: [0.001, 0.001, 0.001]
04-10 08:20:41 Epoch: 5 [320/2462], Train Loss: 0.1636 Train Acc: 0.9384,8528.5 examples/sec 0.01 sec/batch
04-10 08:20:41 Epoch: 5 source_train-Loss: 0.1103 source_train-Acc: 0.9630, Cost 0.2 sec
04-10 08:20:41 Epoch: 5 source_val-Loss: 0.0370 source_val-Acc: 0.9870, Cost 0.0 sec
04-10 08:20:41 Epoch: 5 target_val-Loss: 0.0483 target_val-Acc: 0.9923, Cost 0.0 sec
04-10 08:20:41 -----Epoch 6/299-----
04-10 08:20:41 current lr: [0.001, 0.001, 0.001]
04-10 08:20:41 Epoch: 6 [1024/2462], Train Loss: 0.0950 Train Acc: 0.9694,10124.8 examples/sec 0.01 sec/batch
04-10 08:20:42 Epoch: 6 source_train-Loss: 0.0698 source_train-Acc: 0.9748, Cost 0.2 sec
04-10 08:20:42 Epoch: 6 source_val-Loss: 0.0490 source_val-Acc: 0.9821, Cost 0.0 sec
04-10 08:20:42 Epoch: 6 target_val-Loss: 0.0351 target_val-Acc: 0.9923, Cost 0.0 sec
04-10 08:20:42 -----Epoch 7/299-----
04-10 08:20:42 current lr: [0.001, 0.001, 0.001]
04-10 08:20:42 Epoch: 7 [1728/2462], Train Loss: 0.0654 Train Acc: 0.9776,9923.3 examples/sec 0.01 sec/batch
04-10 08:20:42 Epoch: 7 source_train-Loss: 0.0675 source_train-Acc: 0.9777, Cost 0.2 sec
04-10 08:20:42 Epoch: 7 source_val-Loss: 0.0623 source_val-Acc: 0.9821, Cost 0.0 sec
04-10 08:20:42 Epoch: 7 target_val-Loss: 0.0293 target_val-Acc: 0.9885, Cost 0.0 sec
04-10 08:20:42 -----Epoch 8/299-----
04-10 08:20:42 current lr: [0.001, 0.001, 0.001]
04-10 08:20:42 Epoch: 8 [1140/2462], Train Loss: 0.0745 Train Acc: 0.9757,10340.1 examples/sec 0.01 sec/batch
04-10 08:20:42 Epoch: 8 source_train-Loss: 0.0735 source_train-Acc: 0.9760, Cost 0.2 sec
04-10 08:20:42 Epoch: 8 source_val-Loss: 0.0178 source_val-Acc: 0.9968, Cost 0.0 sec
04-10 08:20:42 Epoch: 8 target_val-Loss: 0.0398 target_val-Acc: 0.9847, Cost 0.0 sec
04-10 08:20:42 -----Epoch 9/299-----
04-10 08:20:42 current lr: [0.001, 0.001, 0.001]
