04-10 08:20:51 method: multiDA
04-10 08:20:51 model_name: cnn_features_1d
04-10 08:20:51 data_name: multi_CWRU
04-10 08:20:51 data_dir: /home/workspace/UDA_Bearing_Fault_Diagnosis/Data/CWRU/
04-10 08:20:51 transfer_task: [[1, 2], [0]]
04-10 08:20:51 normlizetype: mean-std
04-10 08:20:51 adabn: False
04-10 08:20:51 eval_all: False
04-10 08:20:51 adabn_epochs: 3
04-10 08:20:51 cuda_device: 0
04-10 08:20:51 checkpoint_dir: ./checkpoint
04-10 08:20:51 pretrained: False
04-10 08:20:51 batch_size: 64
04-10 08:20:51 num_workers: 0
04-10 08:20:51 bottleneck: True
04-10 08:20:51 bottleneck_num: 256
04-10 08:20:51 last_batch: False
04-10 08:20:51 distance_metric: False
04-10 08:20:51 distance_loss: MK-MMD
04-10 08:20:51 trade_off_distance: Step
04-10 08:20:51 lam_distance: 1
04-10 08:20:51 domain_adversarial: False
04-10 08:20:51 adversarial_loss: CDA+E
04-10 08:20:51 hidden_size: 1024
04-10 08:20:51 trade_off_adversarial: Step
04-10 08:20:51 lam_adversarial: 1
04-10 08:20:51 opt: adam
04-10 08:20:51 lr: 0.001
04-10 08:20:51 momentum: 0.9
04-10 08:20:51 weight_decay: 1e-05
04-10 08:20:51 lr_scheduler: step
04-10 08:20:51 gamma: 0.1
04-10 08:20:51 steps: 150, 250
04-10 08:20:51 middle_epoch: 50
04-10 08:20:51 max_epoch: 300
04-10 08:20:51 print_step: 50
04-10 08:20:51 using 1 gpus
04-10 08:20:54 -----Epoch 0/299-----
04-10 08:20:54 current lr: [0.001, 0.001, 0.001]
04-10 08:20:54 Epoch: 0 [0/2462], Train Loss: 2.4388 Train Acc: 0.0781,1606.7 examples/sec 0.04 sec/batch
04-10 08:20:54 Epoch: 0 source_train-Loss: 1.5545 source_train-Acc: 0.4476, Cost 0.2 sec
04-10 08:20:54 Epoch: 0 source_val-Loss: 0.8879 source_val-Acc: 0.6916, Cost 0.0 sec
04-10 08:20:54 Epoch: 0 target_val-Loss: 1.0672 target_val-Acc: 0.6513, Cost 0.0 sec
04-10 08:20:54 -----Epoch 1/299-----
04-10 08:20:54 current lr: [0.001, 0.001, 0.001]
04-10 08:20:55 Epoch: 1 [704/2462], Train Loss: 1.3870 Train Acc: 0.4984,10222.4 examples/sec 0.01 sec/batch
04-10 08:20:55 Epoch: 1 source_train-Loss: 0.7448 source_train-Acc: 0.7063, Cost 0.2 sec
04-10 08:20:55 Epoch: 1 source_val-Loss: 0.2868 source_val-Acc: 0.9302, Cost 0.0 sec
04-10 08:20:55 Epoch: 1 target_val-Loss: 0.4362 target_val-Acc: 0.8199, Cost 0.0 sec
04-10 08:20:55 -----Epoch 2/299-----
04-10 08:20:55 current lr: [0.001, 0.001, 0.001]
04-10 08:20:55 Epoch: 2 [1408/2462], Train Loss: 0.5488 Train Acc: 0.7805,10916.1 examples/sec 0.01 sec/batch
04-10 08:20:55 Epoch: 2 source_train-Loss: 0.3900 source_train-Acc: 0.8424, Cost 0.2 sec
04-10 08:20:55 Epoch: 2 source_val-Loss: 0.1537 source_val-Acc: 0.9659, Cost 0.0 sec
04-10 08:20:55 Epoch: 2 target_val-Loss: 0.2841 target_val-Acc: 0.8697, Cost 0.0 sec
04-10 08:20:55 -----Epoch 3/299-----
04-10 08:20:55 current lr: [0.001, 0.001, 0.001]
04-10 08:20:55 Epoch: 3 [2112/2462], Train Loss: 0.2576 Train Acc: 0.9002,10846.7 examples/sec 0.01 sec/batch
04-10 08:20:55 Epoch: 3 source_train-Loss: 0.2175 source_train-Acc: 0.9175, Cost 0.2 sec
04-10 08:20:55 Epoch: 3 source_val-Loss: 0.0641 source_val-Acc: 0.9838, Cost 0.0 sec
04-10 08:20:55 Epoch: 3 target_val-Loss: 0.1199 target_val-Acc: 0.9655, Cost 0.0 sec
04-10 08:20:55 -----Epoch 4/299-----
04-10 08:20:55 current lr: [0.001, 0.001, 0.001]
04-10 08:20:55 Epoch: 4 source_train-Loss: 0.1405 source_train-Acc: 0.9529, Cost 0.2 sec
04-10 08:20:55 Epoch: 4 source_val-Loss: 0.0470 source_val-Acc: 0.9870, Cost 0.0 sec
04-10 08:20:55 Epoch: 4 target_val-Loss: 0.0549 target_val-Acc: 0.9885, Cost 0.0 sec
04-10 08:20:55 -----Epoch 5/299-----
04-10 08:20:55 current lr: [0.001, 0.001, 0.001]
04-10 08:20:55 Epoch: 5 [320/2462], Train Loss: 0.1437 Train Acc: 0.9518,9491.1 examples/sec 0.01 sec/batch
04-10 08:20:56 Epoch: 5 source_train-Loss: 0.1296 source_train-Acc: 0.9574, Cost 0.2 sec
04-10 08:20:56 Epoch: 5 source_val-Loss: 0.0249 source_val-Acc: 0.9935, Cost 0.0 sec
04-10 08:20:56 Epoch: 5 target_val-Loss: 0.0708 target_val-Acc: 0.9655, Cost 0.0 sec
04-10 08:20:56 -----Epoch 6/299-----
04-10 08:20:56 current lr: [0.001, 0.001, 0.001]
04-10 08:20:56 Epoch: 6 [1024/2462], Train Loss: 0.1138 Train Acc: 0.9634,10845.3 examples/sec 0.01 sec/batch
04-10 08:20:56 Epoch: 6 source_train-Loss: 0.1016 source_train-Acc: 0.9639, Cost 0.2 sec
04-10 08:20:56 Epoch: 6 source_val-Loss: 0.0691 source_val-Acc: 0.9789, Cost 0.0 sec
04-10 08:20:56 Epoch: 6 target_val-Loss: 0.0493 target_val-Acc: 0.9847, Cost 0.0 sec
04-10 08:20:56 -----Epoch 7/299-----
04-10 08:20:56 current lr: [0.001, 0.001, 0.001]
04-10 08:20:56 Epoch: 7 [1728/2462], Train Loss: 0.0927 Train Acc: 0.9662,10934.9 examples/sec 0.01 sec/batch
04-10 08:20:56 Epoch: 7 source_train-Loss: 0.0900 source_train-Acc: 0.9679, Cost 0.2 sec
04-10 08:20:56 Epoch: 7 source_val-Loss: 0.0078 source_val-Acc: 1.0000, Cost 0.0 sec
04-10 08:20:56 Epoch: 7 target_val-Loss: 0.0508 target_val-Acc: 0.9770, Cost 0.0 sec
04-10 08:20:56 -----Epoch 8/299-----
04-10 08:20:56 current lr: [0.001, 0.001, 0.001]
04-10 08:20:56 Epoch: 8 [1140/2462], Train Loss: 0.0893 Train Acc: 0.9706,10837.5 examples/sec 0.01 sec/batch
04-10 08:20:56 Epoch: 8 source_train-Loss: 0.0776 source_train-Acc: 0.9752, Cost 0.2 sec
04-10 08:20:56 Epoch: 8 source_val-Loss: 0.0131 source_val-Acc: 0.9935, Cost 0.0 sec
04-10 08:20:56 Epoch: 8 target_val-Loss: 0.0407 target_val-Acc: 0.9847, Cost 0.0 sec
04-10 08:20:56 -----Epoch 9/299-----
04-10 08:20:56 current lr: [0.001, 0.001, 0.001]
04-10 08:20:57 Epoch: 9 source_train-Loss: 0.0517 source_train-Acc: 0.9813, Cost 0.2 sec
04-10 08:20:57 Epoch: 9 source_val-Loss: 0.0044 source_val-Acc: 0.9984, Cost 0.0 sec
04-10 08:20:57 Epoch: 9 target_val-Loss: 0.0376 target_val-Acc: 0.9808, Cost 0.0 sec
04-10 08:20:57 -----Epoch 10/299-----
04-10 08:20:57 current lr: [0.001, 0.001, 0.001]
04-10 08:20:57 Epoch: 10 [640/2462], Train Loss: 0.0497 Train Acc: 0.9820,9380.2 examples/sec 0.01 sec/batch
